import streamlit as st
from PIL import Image
import requests
from io import BytesIO
import base64

# -------------------------------
# è¨­å®š
# -------------------------------
API_URL = "https://api-inference.huggingface.co/models/CompVis/stable-diffusion-v1-4"
API_TOKEN = "YOUR_HUGGING_FACE_API_KEY"  # è‡ªåˆ†ã®ã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„

headers = {"Authorization": f"Bearer {API_TOKEN}"}

# -------------------------------
# ã‚µã‚¤ãƒ‰ãƒãƒ¼
# -------------------------------
st.sidebar.title("Fashion Studio AI")
st.sidebar.write("ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ç”»åƒã‚’ç”Ÿæˆã§ãã¾ã™")

# -------------------------------
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆ
# -------------------------------
if "step" not in st.session_state:
    st.session_state.step = 1
if "source_image" not in st.session_state:
    st.session_state.source_image = None
if "target_image" not in st.session_state:
    st.session_state.target_image = None
if "current_image" not in st.session_state:
    st.session_state.current_image = None
if "history" not in st.session_state:
    st.session_state.history = []

# -------------------------------
# ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ç”»é¢
# -------------------------------
def generate_image(prompt, init_image=None):
    payload = {
        "inputs": prompt,
        "options": {"wait_for_model": True},
    }
    if init_image:
        buffered = BytesIO()
        init_image.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
        payload["inputs"] = {"prompt": prompt, "init_image": img_str, "strength":0.7}
    
    response = requests.post(API_URL, headers=headers, json=payload)
    if response.status_code == 200:
        result = response.json()
        # çµæœã®ç”»åƒã‚’å–å¾—
        img_data = base64.b64decode(result["data"][0]["image_base64"])
        return Image.open(BytesIO(img_data))
    else:
        st.error(f"ç”Ÿæˆå¤±æ•—: {response.status_code}")
        return None

st.title("ğŸŒ¸ Fashion Studio AI ğŸŒ¸")

# ã‚¹ãƒ†ãƒƒãƒ—1: ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
if st.session_state.step == 1:
    st.subheader("Step 1: ãƒ¢ãƒ‡ãƒ«ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded = st.file_uploader("äººç‰©ç”»åƒã‚’é¸æŠ", type=["png","jpg","jpeg"])
    if uploaded:
        img = Image.open(uploaded)
        st.session_state.source_image = img
        st.session_state.current_image = img
        st.session_state.step += 1

# ã‚¹ãƒ†ãƒƒãƒ—2: æœè£…ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
elif st.session_state.step == 2:
    st.subheader("Step 2: æœè£…ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded = st.file_uploader("æœè£…ç”»åƒã‚’é¸æŠ", type=["png","jpg","jpeg"])
    if uploaded:
        img = Image.open(uploaded)
        st.session_state.target_image = img
        st.session_state.step += 1

# ã‚¹ãƒ†ãƒƒãƒ—3: ç”»è§’ãƒ»ãƒãƒ¼ã‚ºé¸æŠ
elif st.session_state.step == 3:
    st.subheader("Step 3: ç”»è§’ãƒ»ãƒãƒ¼ã‚ºé¸æŠ")
    angles = [f"{i}Â°ã‚¢ãƒ³ã‚°ãƒ«" for i in range(1,81)]
    selected_angle = st.selectbox("ç”»è§’ã‚’é¸æŠ", angles)
    pose_options = ["æ­£é¢","æ–œã‚ä¸Š","æ–œã‚ä¸‹","ã‚¢ãƒƒãƒ—","è‡ªæ’®ã‚Šé¢¨"]  # å¿…è¦ãªã‚‰æ‹¡å¼µ
    selected_pose = st.selectbox("ãƒãƒ¼ã‚ºã‚’é¸æŠ", pose_options)
    prompt_text = st.text_area("ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆä»»æ„ï¼‰","")
    if st.button("ç”Ÿæˆ"):
        prompt = f"{selected_pose}, {selected_angle}, {prompt_text}"
        result = generate_image(prompt, init_image=st.session_state.source_image)
        if result:
            st.session_state.history.append(st.session_state.current_image)
            st.session_state.current_image = result
            st.image(result, caption="ç”Ÿæˆçµæœ")
            if st.button("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—"):
                st.session_state.step += 1

# ã‚¹ãƒ†ãƒƒãƒ—4ä»¥é™ã‚‚åŒæ§˜ã«è¿½åŠ å¯èƒ½
# é«ªå‹ãƒ»é«ªè‰²ã€è¡¨æƒ…ã€ãƒ–ãƒ©ãƒ³ãƒ‰ãƒ»å­£ç¯€ã€æœã®è‰²ãªã©
